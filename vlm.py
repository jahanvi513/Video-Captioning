# -*- coding: utf-8 -*-
"""VLM

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bWfrSAyaXKFyxjktxK2EJbuuzBFYemj6
"""

pip install transformers accelerate torch torchvision opencv-python

import cv2
import torch
from transformers import Blip2Processor, Blip2ForConditionalGeneration
from PIL import Image
from torchvision import transforms
import os

device = "cuda" if torch.cuda.is_available() else "cpu"
processor = Blip2Processor.from_pretrained("Salesforce/blip2-flan-t5-xl")
model = Blip2ForConditionalGeneration.from_pretrained("Salesforce/blip2-flan-t5-xl").to(device)

def extract_keyframes(video_path, num_frames=3):
    cap = cv2.VideoCapture(video_path)
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    interval = max(1, frame_count // num_frames)
    frames = []

    for i in range(num_frames):
        frame_num = i * interval
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)
        ret, frame = cap.read()
        if ret:
            image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
            frames.append(image)

    cap.release()
    return frames

def caption_frame(image):
    inputs = processor(images=image, return_tensors="pt").to(device)
    generated_ids = model.generate(**inputs, max_new_tokens=50)
    caption = processor.decode(generated_ids[0], skip_special_tokens=True)
    return caption

def caption_video(video_path):
    print(f"\n[INFO] Processing: {os.path.basename(video_path)}")
    frames = extract_keyframes(video_path)
    captions = [caption_frame(frame) for frame in frames]

    print("\n[DEBUG] Frame Captions:")
    for i, cap in enumerate(captions):
        print(f"  Frame {i+1}: {cap}")

    final_summary = " ".join(captions)
    return final_summary

video_folder = "/content/video-data"
video_files = [f for f in os.listdir(video_folder) if f.endswith(('.avi', '.mp4'))][:10]

results = {}
for video_file in video_files:
    video_path = os.path.join(video_folder, video_file)
    description = caption_video(video_path)
    results[video_file] = description

print("\n=== Video Descriptions ===")
for video, desc in results.items():
    print(f"\n{video}:\n{desc}")